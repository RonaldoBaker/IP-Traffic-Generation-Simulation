{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71dfc09-55e2-4d52-9d95-fd3cc90c8cd8",
   "metadata": {},
   "source": [
    "# Generating flow duration and flow size\n",
    "**NOTE** In this version I am now expanding the neural network to generate a third value: Idle time. This will be used as IAT time kinda to use within the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0c4355-74fa-4577-9cd9-0f198d3df65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd1e0f",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69acc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_LENGTH = 924689\n",
    "BATCH_SIZE = 300\n",
    "NUM_EPOCHS = 40\n",
    "LEARNING_RATE = 0.0001\n",
    "RANDOM_SEED = 77\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRAINING_DATA = \"Training Data\\data.pt\"\n",
    "PATH = \"generator1.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9c90ce-048a-4ff3-8d41-85f6186c1d51",
   "metadata": {},
   "source": [
    "## Discriminator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd78ce3-2777-4efb-bf92-0e957a20f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Input is 2D, first hidden layer is composed of 256 neurons with ReLU activation\n",
    "            nn.Linear(3, 128), \n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Have to use dropout to avoid overfitting\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            # second and third layers are composed to 128 and 64 neurons, respectively\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # output is composed of a single neuron with sigmoidal activation to represent a probability\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547cb7a-56f0-4b1f-aff1-ca168eb01bdc",
   "metadata": {},
   "source": [
    "## Generator class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e1c245-c009-465e-a40d-8fd2bc95013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(3, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e236293",
   "metadata": {},
   "source": [
    "## Weights and biases function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_biases_init(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Linear\") != -1:\n",
    "        nn.init.kaiming_normal_(model.weight, mode='fan_in', nonlinearity='relu')\n",
    "        nn.init.zeros_(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa6d065-6b33-41f5-b245-d4a97b34770a",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc00355-4dc6-4c0d-a3d1-ff39b5e8a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_length(data, length):\n",
    "    return data[:length]\n",
    "    \n",
    "def load_data():\n",
    "    data = torch.load(\"data.pt\")\n",
    "    data = data.to(torch.float32)\n",
    "    train_data = train_data_length(data,TRAINING_DATA_LENGTH)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ce02bc-0c1f-4c4b-ac37-1acfc41c9ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_data = load_data()\n",
    "train_data = train_data.to(DEVICE)\n",
    "train_labels = torch.zeros(TRAINING_DATA_LENGTH)\n",
    "train_labels = train_labels.to(DEVICE)\n",
    "train_set = [(train_data[i], train_labels[i]) for i in range(TRAINING_DATA_LENGTH)]\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "     \n",
    "    return \"%d hours %02d mins %02d secs\" % (hour, minutes, seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc93ec2-f3be-4c41-a43e-d2463cbe0073",
   "metadata": {},
   "source": [
    "## Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa85e441-c3dd-4ced-89c5-23e6d41f11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Before training the models, need to define some parameters\n",
    "loss_function = nn.BCELoss()\n",
    "optimiser_discriminator = optim.Adam(discriminator.parameters(), lr = LEARNING_RATE)\n",
    "optimiser_generator = optim.Adam(generator.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "# Create empty loss lists to track values and visualise\n",
    "generator_loss_values = []\n",
    "discriminator_loss_values = []\n",
    "epoch_count = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb985e36-ca7a-4d72-bb4f-6b14790c09e9",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f79842d-2a05-4794-9cc9-594354c1d090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b6fce0ce264decb3b6479d03b6df2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss D.: 50.00044631958008\n",
      "Epoch: 0 Loss G.: 8.099625587463379\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9ca7e263214bdb80acfefae8e231c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6a1ef4fd1448f5ad6262c6539688c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ed65cec53343cc84b153f8cdbb1836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d835dd85e7d49d980a138ec0fb6050d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ccc844524f44c8b591aff944c88b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4ca1926766405d831c5fe7a45cbd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52590c97fa194596bf7455c7d41b8f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e57a6b0ebb444e9a0d9973e4e2fded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78619673dfbe461abe8c112cb854c93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time for 10 epoch(s) is 4.73 seconds.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    # Taking the real samples of the current batch from the data loader and assign them to real_samples\n",
    "    # The first dimension of the tensor has the number of elements equal to the batch size. \n",
    "    # This is the standard way of organising data in PyTorch, with each line of the tensor representing one sample from the batch.\n",
    "    for n, (real_samples, _) in enumerate(tqdm(train_loader)):\n",
    "        # DATA FOR TRAINING THE DISCRIMINATOR\n",
    "\n",
    "        # Using torch.ones() to create labels with the value 1 for real samples, and then assign to real_samples_labels\n",
    "        real_samples_labels = torch.ones((BATCH_SIZE, 1))\n",
    "\n",
    "        # Create the generated samples by storing random data in latent_space_samples\n",
    "        # This is fed into the generator to obtain generated_samples\n",
    "        torch.manual_seed(RANDOM_SEED)\n",
    "        latent_space_samples = torch.randn((BATCH_SIZE, 3))\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "\n",
    "\n",
    "        # Use torch.zeros() to assign 0 to the labels for the generated samples\n",
    "        generated_samples_labels = torch.zeros((BATCH_SIZE, 1))\n",
    "\n",
    "\n",
    "        # Concatenate the real and generated samples and labels and store them in all_samples\n",
    "        # and all_samples_labels to train the discriminator\n",
    "        all_samples = torch.cat((real_samples, generated_samples))\n",
    "        all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "\n",
    "\n",
    "        # TRAINING THE DISCRIMINATOR\n",
    "\n",
    "        # Clear the gradients at each training step to avoid accumulating them\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        # Calculate the output of the discriminator from the training data in all_samples\n",
    "        output_discriminator = discriminator(all_samples)\n",
    "\n",
    "        # Calculate the loss function using discriminator output and all the labels\n",
    "        loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "        \n",
    "        # Calculate the gradients to update the weights\n",
    "        loss_discriminator.backward()\n",
    "\n",
    "        # Update the discriminator weights\n",
    "        optimiser_discriminator.step()\n",
    "\n",
    "\n",
    "\n",
    "        # DATA FOR TRAINING THE GENERATOR\n",
    "        \n",
    "        # Storing random data in latent_space_samples with a number of lines to equal batch_size\n",
    "        torch.manual_seed(RANDOM_SEED)\n",
    "        latent_space_samples = torch.randn((BATCH_SIZE, 3))\n",
    "\n",
    "        # TRAINING THE GENERATOR\n",
    "        generator.zero_grad()\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "\n",
    "        # Feeding generator's output into the discriminator and store its output, which is used\n",
    "        # as the output of the whole model\n",
    "        output_discriminator_generated = discriminator(generated_samples)\n",
    "\n",
    "        # Calculate the loss function\n",
    "        loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "        \n",
    "        # Calculate and update the gradients\n",
    "        # REMEMBER:\n",
    "        # When the generator is trained, the discriminator weights are frozen since optimiser_generator\n",
    "        # was created with its first argument equal to generator.parameters()\n",
    "        loss_generator.backward()\n",
    "        optimiser_generator.step()\n",
    "\n",
    "\n",
    "        # Show loss\n",
    "        if epoch % 10 == 0 and n == BATCH_SIZE - 1:\n",
    "            epoch_count.append(epoch)\n",
    "            generator_loss_values.append(generator_loss.cpu().detach().numpy())\n",
    "            discriminator_loss_values.append(discriminator_loss.cpu().detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | D Loss: {discriminator_loss} | G Loss: {generator_loss}\")\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = round(end_time - start_time, 2)\n",
    "converted_time = conver_time(run_time)\n",
    "print(f\"Run time for {NUM_EPOCHS} epoch(s) is {converted_time} seconds.\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13832657",
   "metadata": {},
   "source": [
    "## Visualising Generator and Discriminator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_count, generator_loss_values, label=\"Generator loss\")\n",
    "plt.plot(epoch_count, discriminator_loss_values, label=\"Discriminator loss\")\n",
    "plt.title(\"Generator and Discriminator loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.savefig(\"Test Results/loss_curve.png\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6235a5db-4dcf-4d0b-a145-bfb2b37701aa",
   "metadata": {},
   "source": [
    "## Generating synthetic data and save generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85c10373-2e33-475e-9dde-5f1b6924df22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Duration      Size\n",
      "0   -0.099430 -0.031040\n",
      "1   -0.116570  0.035047\n",
      "2   -0.287762  0.034298\n",
      "3   -0.164122  0.091254\n",
      "4   -0.078110 -0.051378\n",
      "..        ...       ...\n",
      "995 -0.095357 -0.005502\n",
      "996 -0.110841 -0.021174\n",
      "997 -0.089764 -0.039157\n",
      "998 -0.209945  0.062785\n",
      "999 -0.249876 -0.099508\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "latent_space_samples = torch.randn((1000, 3), device = DEVICE)\n",
    "generated_samples = generator(latent_space_samples)\n",
    "\n",
    "generated_samples = generated_samples.detach().numpy()\n",
    "df = pd.DataFrame(generated_samples, columns = [\"Duration\", \"Size\",\"Idle.Time\"])\n",
    "print(df)\n",
    "df.to_csv(\"Test Results/generated_dur_size_idle.time.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2886c5",
   "metadata": {},
   "source": [
    "## Visualise synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79018cc",
   "metadata": {},
   "source": [
    "### Scatter graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb079af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[\"Size\"], df[\"Duration\"])\n",
    "plt.title(\"Relation betweeen flow duration and flow size in synthetic data\")\n",
    "plt.xlabel(\"Flow Size (bytes)\")\n",
    "plt.ylabel(\"Flow Duration (s)\")\n",
    "plt.savefig(\"Test Results/durationVSsize.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a358f",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e24e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df[\"Duration\"])\n",
    "plt.title(\"Distribution of synthetic flow duration\")\n",
    "plt.xlabel(\"Flow duration (s)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df[\"Size\"])\n",
    "plt.title(\"Distribution of synthetic flow size\")\n",
    "plt.xlabel(\"Flow size (bytes)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"size_dur_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305aef0d",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea381654",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.boxplot(df[\"Duration\"], vert = False)\n",
    "plt.title(\"Distribution of synthetic flow duration\")\n",
    "plt.xlabel(\"Flow duration (ms)\")\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.boxplot(df[\"Size\"], vert = False)\n",
    "plt.title(\"Distribution of synthetic flow size\")\n",
    "plt.xlabel(\"Flow size (bytes)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"size_dur_distribution.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
