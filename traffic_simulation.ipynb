{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702494fa",
   "metadata": {},
   "source": [
    "# Converged and Non-converged Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0f7313",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e40f79d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "import bisect\n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27076846",
   "metadata": {},
   "source": [
    "## Constants and data containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e7ab6eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generation\n",
    "GENERATOR = None\n",
    "GENERATOR_PATH = \"generator5.pt\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "RANDOM_SEED = 77\n",
    "\n",
    "# Network & Flows\n",
    "NETWORK = None\n",
    "BLOCKED = None # count of flows blocked\n",
    "SENT = None # count of flows that reached their destination\n",
    "ADDRESSES = [i for i in range(1,22)]\n",
    "WAVELENGTHS = 40\n",
    "EXPON_SCALE = 0.1\n",
    "EXPON_DIST = np.random.exponential(scale=EXPON_SCALE, size=20000000)\n",
    "\n",
    "# Simulation\n",
    "SIM_CLOCK = None \n",
    "MIN_FLOWS_SENT = 1e2\n",
    "EVENTS_LIST = None\n",
    "ARCHITECTURE = None \n",
    "\n",
    "IAT_TIMES = []\n",
    "DURATIONS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3fcd5e",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55787249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebe92ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvergedNetwork:\n",
    "    def __init__(self, graph, num_of_wavelengths):\n",
    "        self.topology = graph\n",
    "        self.__allocate_capacity__(num_of_wavelengths)\n",
    "    \n",
    "    \n",
    "    def __allocate_capacity__(self, num_of_wavelengths):\n",
    "        self.links = dict()\n",
    "        for edge in self.topology.edges():\n",
    "            node1, node2 = edge[0], edge[1] \n",
    "            self.links[(node1, node2)] = num_of_wavelengths \n",
    "       \n",
    "    \n",
    "    def __check_capacity__(self, node1, node2): \n",
    "        try:\n",
    "            return self.links[(node1, node2)] > 0\n",
    "        except KeyError:\n",
    "            return self.links[(node2, node1)] > 0\n",
    "    \n",
    "    \n",
    "    def __use_capacity__(self, node1, node2):\n",
    "        try: \n",
    "            self.links[(node1, node2)] -= 1\n",
    "        except KeyError:\n",
    "            self.links[(node2, node1)] -= 1\n",
    "\n",
    "            \n",
    "    def __release_capacity__(self, node1, node2):\n",
    "        try:   \n",
    "            self.links[(node1, node2)] += 1\n",
    "        except KeyError:\n",
    "            try:\n",
    "                self.links[(node2, node1)] += 1\n",
    "            except KeyError: # One of the nodes must be None\n",
    "                pass # there is no link to release capacity for\n",
    "                \n",
    "        \n",
    "    def push_flow(self, flow, type):\n",
    "        node1, node2 = flow.current_node, flow.route[0]\n",
    "        if type == \"HOP\":\n",
    "            self.__release_capacity__(flow.prev_node, flow.current_node)\n",
    "            \n",
    "        sufficient_capacity = self.__check_capacity__(node1, node2)\n",
    "        if sufficient_capacity:\n",
    "            self.__use_capacity__(node1, node2)\n",
    "            next_event_type = flow.hop()\n",
    "            return next_event_type, flow \n",
    "        else:\n",
    "            next_event_type = \"BLOCKED\"\n",
    "            return next_event_type, flow\n",
    "            \n",
    "            \n",
    "    def end_flow(self, flow):\n",
    "        node1, node2 = flow.prev_node, flow.current_node\n",
    "        self.__release_capacity__(node1, node2)\n",
    "        # print(f\"Sim Clock: {SIM_CLOCK} seconds | Flow {flow.ID} has reached its destination, node {flow.dst}. Now leaving the network...\")\n",
    "\n",
    "\n",
    "    def find_route(self, src, dst):\n",
    "        return nx.shortest_path(self.topology, source = src, target = dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6458b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonConvergedNetwork:\n",
    "    def __init__(self, graph, num_of_wavelengths):\n",
    "        self.topology = graph\n",
    "        self.__allocate_capacity__(num_of_wavelengths)\n",
    "    \n",
    "    \n",
    "    def __allocate_capacity__(self, num_of_wavelengths):\n",
    "        self.links = dict()\n",
    "        for edge in self.topology.edges():\n",
    "            node1, node2 = edge[0], edge[1]\n",
    "            # Each item in the list will represent a unique wavelength in the link\n",
    "            self.links[(node1, node2)] = [format(i, \"02\") for i in range(1, num_of_wavelengths+1)]\n",
    "            \n",
    "    \n",
    "    def __check_capacity__(self, node1, node2):\n",
    "        # Return all the available wavelengths\n",
    "        try:\n",
    "            return self.links[(node1, node2)]\n",
    "        except KeyError:\n",
    "            return self.links[(node2, node1)]\n",
    "    \n",
    "    \n",
    "    def __use_capacity__(self, node1, node2, wavelength):\n",
    "        try: \n",
    "            self.links[(node1, node2)].remove(wavelength)\n",
    "        except KeyError:\n",
    "            self.links[(node2, node1)].remove(wavelength) \n",
    "\n",
    "            \n",
    "    def __release_capacity__(self, node1, node2, wavelength):\n",
    "        try:   \n",
    "            self.links[(node1, node2)].append(wavelength)\n",
    "        except KeyError:\n",
    "            self.links[(node2, node1)].append(wavelength)\n",
    "            \n",
    "                \n",
    "    def find_route(self, src, dst):\n",
    "        return nx.shortest_path(self.topology, source = src, target = dst)\n",
    "    \n",
    "    \n",
    "    def __wavelength_assignment__(self, flow):\n",
    "        wavelength_counter = dict()\n",
    "        viable_lightpaths = []\n",
    "\n",
    "        for link in flow.lightpath:\n",
    "            available_wavelengths = self.__check_capacity__(link[0], link[1])\n",
    "            for wavelength in available_wavelengths:\n",
    "                wavelength_counter[wavelength] = wavelength_counter.get(wavelength,0) + 1\n",
    "\n",
    "        for key in wavelength_counter.keys():\n",
    "            if wavelength_counter[key] == len(flow.lightpath): # Pick the first wavelength that is available on all the links in the path\n",
    "                flow.wavelength = key\n",
    "                return flow\n",
    "            \n",
    "        flow.wavelength = \"00\"\n",
    "        return flow\n",
    "        \n",
    "    def push_flow(self, flow):\n",
    "        updated_flow = self.__wavelength_assignment__(flow)\n",
    "        if updated_flow.wavelength == \"00\":\n",
    "            return \"BLOCKED\", updated_flow\n",
    "        \n",
    "        else:\n",
    "            # Uses lightpath from flow to update the capacity on each link in the lightpath\n",
    "            for link in updated_flow.lightpath:\n",
    "                self.__use_capacity__(link[0], link[1], updated_flow.wavelength)\n",
    "            return \"DEPART\", updated_flow\n",
    "\n",
    "        \n",
    "    def end_flow(self, flow):\n",
    "        for link in flow.lightpath:\n",
    "            self.__release_capacity__(link[0], link[1], flow.wavelength)\n",
    "        # print(f\"Sim Clock: {SIM_CLOCK} seconds | Flow {flow.ID} has reached its destination, node {flow.dst}. Now leaving the network...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8537a11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvergedFlow:\n",
    "    def __init__(self):\n",
    "        # self.parent_net = network\n",
    "        self.__create_flow__()\n",
    "        \n",
    "    def __generate_data__(self):\n",
    "        torch.manual_seed(RANDOM_SEED)\n",
    "        random_noise = torch.randn((1, 2), device = DEVICE)\n",
    "        generated_samples = GENERATOR(random_noise)\n",
    "        generated_samples = generated_samples.cpu().detach().numpy()\n",
    "        synthetic_dur, synthetic_size = generated_samples[0,0], generated_samples[0,1]\n",
    "        return synthetic_dur, synthetic_size\n",
    "        \n",
    "    def __create_convflow__(self):\n",
    "        self.dur, self.size = self.__generate_data__()\n",
    "        random_addresses = random.sample(ADDRESSES, 2)\n",
    "        self.src, self.dst = random_addresses[0], random_addresses[1]\n",
    "        self.current_node = self.src\n",
    "        self.prev_node = None\n",
    "        \n",
    "        # Calculate shortest path\n",
    "        self.route = NETWORK.find_route(self.src, self.dst)\n",
    "        \n",
    "        # Removes the first node in the route which is the starting node for the flow path \n",
    "        self.route = self.route[1:] \n",
    "        \n",
    "        # How long it will take to make each hop, used to schedule the next event time\n",
    "        self.hop_time = self.dur / len(self.route) \n",
    "        \n",
    "        \n",
    "    def hop(self): # Pushes the flow into the network from src to dst/from one hop to the next\n",
    "        self.prev_node = self.current_node \n",
    "        # print(f\"Sim Clock: {SIM_CLOCK} seconds | Flow {self.ID} is moving from node {self.current_node} to node {self.route[0]}.\")\n",
    "        self.current_node = self.route.pop(0)\n",
    "        \n",
    "        if len(self.route) == 0:\n",
    "            # print(f\"Flow {self.ID} has reached its destination, node {self.dst}. Now leaving the network...\")\n",
    "            next_event_type = \"DEPART\"\n",
    "        else:\n",
    "            next_event_type = \"HOP\"\n",
    "        \n",
    "        return next_event_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a4bee158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonConvergedFlow:\n",
    "    def __init__(self):\n",
    "        self.__create_flow__()\n",
    "        \n",
    "    def __generate_data__(self):\n",
    "        torch.manual_seed(RANDOM_SEED)\n",
    "        random_noise = torch.randn((1, 2), device = DEVICE)\n",
    "        generated_samples = GENERATOR(random_noise)\n",
    "        generated_samples = generated_samples.cpu().detach().numpy()\n",
    "        synthetic_dur, synthetic_size = generated_samples[0,0], generated_samples[0,1]\n",
    "        return synthetic_dur, synthetic_size\n",
    "        \n",
    "    def __create_flow__(self):\n",
    "        self.wavelength = \"\"\n",
    "        self.dur, self.size = self.__generate_data__()\n",
    "        random_addresses = random.sample(ADDRESSES, 2)\n",
    "        self.src, self.dst = random_addresses[0], random_addresses[1]\n",
    "        \n",
    "        # Calculate shortest path\n",
    "        self.route = NETWORK.find_route(self.src, self.dst)\n",
    "        \n",
    "        # Define a lightpath for the flow from its node pairs\n",
    "        self.lightpath = []\n",
    "        for i in range(len(self.route)):\n",
    "            try:\n",
    "                self.lightpath.append((self.route[i], self.route[i+1]))\n",
    "            except IndexError: # Gotten to the end of the path list and has accounted for all the links\n",
    "                pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2cd164a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Event:\n",
    "    def __init__(self, event_time, event_type, flow):\n",
    "        self.event_type = event_type # ARRIVAL, DEPARTURE, HOP OR BLOCKED\n",
    "        self.event_time = event_time # When the event will happen in simulated time\n",
    "        self.associated_flow = flow # The same flow is attached to an Event object, only type and time changes throughout the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af8385-eb18-45e5-98ee-07a915bcafaa",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdc52212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def schedule_event(event_time, event_type, associated_flow):\n",
    "    global EVENTS_LIST\n",
    "    \n",
    "    # Create new event\n",
    "    new_event = Event(event_time, event_type, associated_flow)\n",
    "    \n",
    "    # Create key with which the events list will be sorted; will be sorted by event time\n",
    "    time_key = operator.attrgetter(\"event_time\")\n",
    "    \n",
    "    # Inserts a new event into the Events list and maintains its sorted order\n",
    "    bisect.insort(EVENTS_LIST, new_event, key=time_key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b073f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialise_simulation():\n",
    "    global SIM_CLOCK, GENERATOR, NETWORK, BLOCKED, SENT, EVENTS_LIST, ARCHITECTURE\n",
    "    \n",
    "    EVENTS_LIST = []\n",
    "    # Set simulation clock to 0\n",
    "    SIM_CLOCK = 0\n",
    "    # global sim_clock, generator, network, BLOCKED, SENT\n",
    "\n",
    "    # Initialise the generator\n",
    "    GENERATOR = Generator()\n",
    "    GENERATOR.load_state_dict(torch.load(GENERATOR_PATH, map_location=DEVICE))\n",
    "    GENERATOR = GENERATOR.to(DEVICE)\n",
    "    \n",
    "    # Initialise the network\n",
    "    G = nx.read_adjlist(\"UKnet\", nodetype=int)\n",
    "    \n",
    "    NETWORK = ConvergedNetwork(G, WAVELENGTHS) if ARCHITECTURE==\"CONVERGED\" else NonConvergedNetwork(G, WAVELENGTHS)\n",
    "    \n",
    "    # Initialise statistical counters\n",
    "    BLOCKED = 0\n",
    "    SENT = 0\n",
    "\n",
    "    # Add one event to the list to start the simulation\n",
    "    new_flow = ConvergedFlow() if ARCHITECTURE==\"CONVERGED\" else NonConvergedFlow()\n",
    "    DURATIONS.append(new_flow.dur)\n",
    "    schedule_event(event_time = 0, event_type = \"ARRIVAL\", associated_flow = new_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53dc2992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the next event in the list and advance simulation clock\n",
    "def timing_routine():\n",
    "    global SIM_CLOCK\n",
    "    # Popping the next event from the top of the list\n",
    "    next_event = EVENTS_LIST.pop(0)\n",
    "    \n",
    "    # Accessing the time of the next scheduled event\n",
    "    advanced_time = next_event.event_time\n",
    "    \n",
    "    # Advancing the simulation clock to the time of the next scheduled event\n",
    "    SIM_CLOCK = advanced_time\n",
    "    \n",
    "    return next_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48f4e1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def event_routine(event):\n",
    "    global SIM_CLOCK, NETWORK, SENT, BLOCKED, ARCHITECTURE\n",
    "\n",
    "    current_flow = event.associated_flow\n",
    "    \n",
    "    if event.event_type == \"ARRIVAL\" or event.event_type == \"HOP\":\n",
    "        \n",
    "        if ARCHITECTURE==\"CONVERGED\":\n",
    "            # Allow the network to push the flow to the next node\n",
    "            next_event_type, updated_flow = NETWORK.push_flow(current_flow, event.event_type)\n",
    "        \n",
    "            if next_event_type != \"BLOCKED\": # if blocked, there's no new event to schedule and capacity in the previous link has been released.\n",
    "                schedule_event(SIM_CLOCK+updated_flow.hop_time, next_event_type, associated_flow = updated_flow)\n",
    "            else:\n",
    "                BLOCKED += 1\n",
    "                \n",
    "        else:\n",
    "            next_event_type, updated_flow = NETWORK.push_flow(current_flow)\n",
    "            if next_event_type == \"DEPART\":\n",
    "                schedule_event(SIM_CLOCK + updated_flow.dur, \"DEPART\", updated_flow) \n",
    "            else:\n",
    "                BLOCKED += 1\n",
    "\n",
    "    else: # Departure event\n",
    "        NETWORK.end_flow(current_flow)\n",
    "        SENT += 1\n",
    "    \n",
    "    # Only generating new arrival events when the current event is an arrival so that the iat is used correctly.\n",
    "    if event.event_type == \"ARRIVAL\":\n",
    "        \n",
    "    # Generate a future arrival event and add to the events list\n",
    "        new_flow = ConvergedFlow() if ARCHITECTURE==\"CONVERGED\" else NonConvergedFlow()\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        iat = np.random.choice(EXPON_DIST)\n",
    "        IAT_TIMES.append(iat) # To calculate the average IAT to calculate the load (Erlangs)\n",
    "        schedule_event(event_time = SIM_CLOCK + iat, event_type = \"ARRIVAL\", associated_flow = new_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "420031b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "     \n",
    "    return \"%d hours %02d mins %02d secs\" % (hour, minutes, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23289eb7-c5c1-4dbb-92c0-52c3651b6e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def report(run_time):\n",
    "    global IAT_TIMES, DURATIONS\n",
    "    sim_time = convert_time(run_time)\n",
    "    blocked_flows = round(BLOCKED*100/(BLOCKED+SENT), 4)\n",
    "    sent_flows = 100 - blocked_flows\n",
    "    \n",
    "    IAT_TIMES = np.array(IAT_TIMES)\n",
    "    mean_iat  = np.mean(IAT_TIMES)\n",
    "    \n",
    "    DURATIONS = np.array(DURATIONS)\n",
    "    mean_dur  = np.mean(DURATIONS)\n",
    "    \n",
    "    print(f\"The simulation took {sim_time} to complete\")\n",
    "    print(f\"Total flows travelled through the network: {BLOCKED + SENT}\")\n",
    "    print(f\"{sent_flows} % of all flows arrived successfully to its destination, {SENT} flows\")\n",
    "    print(f\"{blocked_flows} % of all flows were blocked due to lack of capacity in a link, {BLOCKED} flows\")\n",
    "    print()\n",
    "    print(f\"The average interarrival time of a flow was {round(mean_iat,3)} seconds\")\n",
    "    print(f\"The average duration of a flow was {round(mean_dur,3)} seconds\")\n",
    "    print(f\"The traffic load of this simulation was {round(mean_dur/mean_iat,3)} erlangs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4532e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_architecture():\n",
    "    print(\"What kind of architecture would you like to simulate today?\")\n",
    "    print(\"1. Converged\\n2. Non-converged\")\n",
    "    print(\"Enter '1' for converged or '2' for non-converged\")\n",
    "    while True:\n",
    "        try:\n",
    "            architecture = int(input())\n",
    "            if 0 < architecture < 3:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Choice must be 1 or 2. Try again.\")\n",
    "        except:\n",
    "            print(\"Choice must be an integer. Try again.\")\n",
    "            \n",
    "    return \"CONVERGED\" if (architecture==1) else \"NONCONVERGED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2fc89800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main function for testing purposes\n",
    "def main():\n",
    "    ARCHITECTURE = choose_architecture()\n",
    "    print(F\"Starting {ARCHITECTURE} simulation...\")\n",
    "    start_time = time.time()\n",
    "    initialise_simulation()\n",
    "    \n",
    "    progress = 0\n",
    "    progress_bar = tqdm(total=MIN_FLOWS_SENT, desc=\"Simulating\", unit = \" flows sent\", leave=False)\n",
    "    \n",
    "    while (SENT + BLOCKED) < MIN_FLOWS_SENT:\n",
    "        next_event = timing_routine()\n",
    "        event_routine(next_event)\n",
    "        progress = SENT + BLOCKED\n",
    "        progress_bar.update(progress - progress_bar.n)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    run_time = end_time - start_time\n",
    "    report(run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a637fef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of architecture would you like to simulate today?\n",
      "1. Converged\n",
      "2. Non-converged\n",
      "Enter '1' for converged or '2' for non-converged\n",
      "2\n",
      "Starting NONCONVERGED simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The simulation took 0 hours 00 mins 01 secs to complete\n",
      "Total flows travelled through the network: 100\n",
      "0.0 % of all flows arrived successfully to its destination, 0 flows\n",
      "100.0 % of all flows were blocked due to lack of capacity in a link, 100 flows\n",
      "\n",
      "The average interarrival time of a flow was 0.066 seconds\n",
      "The average duration of a flow was 117.10700225830078 seconds\n",
      "The traffic load of this simulation was 1784.324 erlangs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
